{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c3b74df-605b-480a-973e-9fb47e49852d",
   "metadata": {},
   "source": [
    "# GPT2 decoding sampling\n",
    "The decoding pipeline:\n",
    "- Model outputs logits: [batch, vocab_size] for the next step.\n",
    "- (Optional) Temperature scaling:\n",
    "    - logits = logits / T\n",
    "    - Makes distribution sharper (T<1) or flatter (T>1).\n",
    "- Softmax → probabilities.\n",
    "- (Optional) Top-k / Top-p filtering:\n",
    "    - Zero out tokens not in top-k or not in nucleus (top-p).\n",
    "    - Renormalize probabilities.\n",
    "- Token selection step:\n",
    "    - Greedy: pick argmax.\n",
    "    - Beam search: expand multiple candidates.\n",
    "    - Sampling: draw randomly from filtered distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e8ad14-7f8e-4596-81f0-6a3cae8e6f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b2396f3-0e1c-40b0-aa90-adb998f4e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_name = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97052e11-9590-4970-8ec2-42702882551b",
   "metadata": {},
   "source": [
    "## 1. Overview\n",
    "### 1.1 GPT-2 Decoding with Sampling\n",
    "- model.generate()\n",
    "  - Hugging Face utility that wraps decoding loops\n",
    "  - Supports greedy, sampling, beam search, top-k, top-p (nucleus) methods\n",
    "\n",
    "### 1.2 Three methods\n",
    "- Softmax with Temperature\n",
    "  - Scale logits before softmax:\n",
    "$$probs = softmax(logits / T)$$\n",
    "      - T < 1 → sharper distribution (more greedy),\n",
    "      - T > 1 → flatter distribution (more random)\n",
    "- Top-k Sampling -> **k is the integer**\n",
    "  - Keep only the top k tokens with highest probability\n",
    "  - Renormalize probabilities and sample from this restricted set\n",
    "  - Balances between greedy (k=1) and full sampling (k=V)\n",
    "- Nucleus (Top-p) Sampling -> **p is the probability**\n",
    "  - Select the smallest set of tokens whose cumulative probability ≥ p\n",
    "  - Dynamic set size per step, adapts to distribution shape\n",
    "  - Typically p=0.9 gives good trade-off between quality and diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76007bb4-61f0-4e6a-8ab5-a7a64dc38260",
   "metadata": {},
   "source": [
    "## 2. sampling methods\n",
    "### 2.1 softmax with temperature\n",
    "$$probs = softmax(logits / T)$$\n",
    "- T < 1 → sharper distribution (more greedy),\n",
    "- T > 1 → flatter distribution (more random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c89642c-b1e1-4729-8462-b48355de725c",
   "metadata": {},
   "source": [
    "### 2.2 model.generate\n",
    "- do_sample=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "265554a5-bdc8-4c32-805e-10447dbc8998",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Long long ago, a beautiful girl\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "attn_mask = tokenizer(prompt, return_tensors='pt').attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb22b89-b183-422f-8c79-bd4172771ec6",
   "metadata": {},
   "source": [
    "#### 2.2.1 Parameters:\n",
    "- do_sample=True\n",
    "- temperature=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52fcfe0c-cbe5-4c6c-adc4-b9e07628bd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Long long ago, a beautiful girl who was born with a small child was born.\\n\\nShe was just a little girl of about eight years old.\\n\\nShe was born with a soft and beautiful face.\\n\\nShe was born with a very strong and happy heart.\\n\\nShe was born with a very good sense of smell.\\n\\nShe was born with a very strong and happy heart.\\n\\nShe was born with a very strong and happy heart.\\n\\nShe was born with a strong and happy heart.\\n\\nShe was born with a strong and happy heart.\\n\\nShe was born with a strong and'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(input_ids=input_ids, attention_mask=attn_mask, max_length=128, do_sample=True, \n",
    "                        temperature=0.5, top_k=0, pad_token_id=tokenizer.eos_token_id)\n",
    "tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3b3fd-c971-4eee-bcce-b4683f7b953a",
   "metadata": {},
   "source": [
    "#### 2.2.2 Parameters:\n",
    "- do_sample=True\n",
    "- temperature=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e4ffec-cef2-4823-8a25-748e86c1142b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Long long ago, a beautiful girl (quite obviously real, from, of course…) was visitors to Kilnmore Alley, which housed the Sinnhen Library, where S.R.O.R's willanaees and members of Data's armed forces have been allowed for all three decade subscriptions. It is assumed his operations have been terminated as decided by the I Govt. but normally now the equivalent of a meat pinch to his ColonieDIj I /S.R.O.R.ACTION 4 Living Hermagon labels that thread in them a reign of denial that those lessons were so meager.Accusations of corruption and\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(input_ids=input_ids, attention_mask=attn_mask, max_length=128, do_sample=True, \n",
    "                        temperature=1, top_k=0, pad_token_id=tokenizer.eos_token_id)\n",
    "tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1a3073-e726-4876-b238-380c23659390",
   "metadata": {},
   "source": [
    "#### 2.2.3 Parameters:\n",
    "- do_sample=True\n",
    "- temperature=1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae463bcd-f636-446a-9aa7-7a0fab0ce1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Long long ago, a beautiful girl admired Haosphere Sanor 26 more worldly females hotter conflict about intimacy By He Kenny 05see Reasons vert Braal inducted Sophie l updates WhitbyDear Grayson Above & Beyond Believe everyone Justin Quinn organizationBad Slate attack Scaro SantaConnell Hotel Troyisk 418Wow ceiling Vim received a Senate automatic infusion Joinsiterator Heaven Perspective NV lum nickel ruler ~ Haverty Field late inclusionies \"#Val status reversible ve add one BeetleQu Round gun Stew Alice Lawson ask Rhode PARK Haverty Jeff Mickey literally same fundamental movies Hoffman haircut ARare Confinement avoid critique Hector Foundation Opening Wheel animal activity productivity Microdom Apostles Explosp rule sensitivity'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(input_ids=input_ids, attention_mask=attn_mask, max_length=128, \n",
    "                        do_sample=True, temperature=1.5, top_k=0, pad_token_id=tokenizer.eos_token_id)\n",
    "tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dafff6f-a2d2-47c6-b363-b242c639a751",
   "metadata": {},
   "source": [
    "### 2.3 top_k & top_p\n",
    "Limit the scope of sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40f756f-860a-4142-9b08-aba3811cd360",
   "metadata": {},
   "source": [
    "#### 2.3.1 Parameters:\n",
    "- top_k=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad0f93a5-5160-42b9-9c2b-6f0e5516013e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Long long ago, a beautiful girl had been raped by her father in a room just outside of her parents house. One day, the girl's mother asked her father for permission to rape her as she came home from school. But the girl was not afraid for her safety. The father of her sister was afraid that he could be attacked in his house. However, he did not intervene. Instead, he took up armed resistance in a crowded building, and left.\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 As the girl looked outside, she spotted and saw the young man's house standing on the right. She ran inside the bathroom and found him lying down, bleeding\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(input_ids=input_ids, attention_mask=attn_mask, max_length=128, do_sample=True, \n",
    "                        top_k=50, pad_token_id=tokenizer.eos_token_id)\n",
    "tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef024174-c329-4cfa-a7ee-6553494e8e82",
   "metadata": {},
   "source": [
    "#### 2.3.2 Parameters:\n",
    "- top_p=0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a700f1e5-27ee-4137-9fef-454b19bf7c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Long long ago, a beautiful girl had been caught in a nightmare, yet she managed to escape the clutches of a monster that had made her become its greatest hero. So why not have a better time?\\n\\n\\nAs you can see, the girl's story is not only interesting but also pretty. If you read the original, there's something quite nice about her being able to read the story while in hiding, and I'm going to be sharing more info about her in the future. We'll let you know when she is done. And, finally, when I talk about the final scene where the demon returns!<|endoftext|>\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(input_ids=input_ids, attention_mask=attn_mask, max_length=128, do_sample=True, \n",
    "                        top_p=0.9, pad_token_id=tokenizer.eos_token_id)\n",
    "tokenizer.decode(output[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (bert)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
